# -*- coding: utf-8 -*-
"""DeteccionBostezo_IA2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12iG81REirWQ9wg5mgaak8hvct084GTtv
"""

import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
import random
from skimage.feature import hog
from skimage import exposure, io, color
from hashlib import md5
from PIL import Image
from sklearn.utils import shuffle
from sklearn.svm import SVC
import seaborn as sns
from skimage.feature import hog
from skimage import exposure, io, color
from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing import image
from sklearn.metrics import classification_report, confusion_matrix
from skimage import exposure
from keras.preprocessing.image import ImageDataGenerator
from skimage.feature import hog
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.utils import to_categorical
from tensorflow.keras.models import load_model

from google.colab import files
uploaded = files.upload()

import zipfile # leer y escribir con archivos zip
import io # tener acceso a los archivos
data = zipfile.ZipFile(io.BytesIO(uploaded['datasetv1.zip']), 'r') # Leer el archivo 'r'
data.extractall() # extraer los archivos.

yawn_dir = "/content/dataset/yawn"
no_yawn_dir = "/content/dataset/no yawn"

def visualize_images(directory, num_images=5):
    # Obtener una lista de nombres de archivos en el directorio
    file_list = os.listdir(directory)[:num_images]
    # Configurar la cuadrícula de subgráficos
    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))
    for i, filename in enumerate(file_list):
        # Cargar y mostrar cada imagen
        path = os.path.join(directory, filename)
        img = Image.open(path)
        axes[i].imshow(img)
        axes[i].axis('off')  # Desactivar ejes para mayor claridad

    plt.show()

visualize_images(yawn_dir, num_images=5)

"""# *Redimensionamiento* de imagenes"""

def resize_images(directory, target_size):
    for filename in os.listdir(directory):
        path = os.path.join(directory, filename)
        img = Image.open(path)
        img_resized = img.resize(target_size)
        img_resized.save(path)

target_size = (200, 200)
resize_images(yawn_dir, target_size)
resize_images(no_yawn_dir, target_size)

visualize_images(yawn_dir, num_images=10)

def count_imgs(directorio):
    if not os.path.exists(directorio):
        print(f"El directorio {directorio} no existe.")
        return 0
    # Contador de imágenes
    num_imagenes = 0
    # Recorrer los archivos en el directorio
    for filename in os.listdir(directorio):
        path = os.path.join(directorio, filename)
        # Verificar si el elemento es un archivo y tiene una extensión de imagen
        if os.path.isfile(path) and any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):
            num_imagenes += 1
    return num_imagenes

def find_duplicates(directorio):
    hash_imagenes = {}
    # Lista para almacenar las imágenes duplicadas
    duplicadas = []
    # Recorrer los archivos en el directorio
    for filename in os.listdir(directorio):
        path = os.path.join(directorio, filename)
        # Verificar si el elemento es un archivo y tiene una extensión de imagen
        if os.path.isfile(path) and any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):
            # Calcular el hash MD5 de la imagen
            with open(path, 'rb') as f:
                hash_imagen = md5(f.read()).hexdigest()
            # Verificar duplicados
            if hash_imagen in hash_imagenes:
                duplicadas.append(path)
            else:
                hash_imagenes[hash_imagen] = path
    return duplicadas

def delete_duplicate(duplicadas):
    # Eliminar las imágenes duplicadas
    for duplicada in duplicadas:
        os.remove(duplicada)
    print(f"Total de imágenes duplicadas eliminadas: {len(duplicadas)}")

# Ejemplo de uso
delete_duplicate(find_duplicates(yawn_dir))
delete_duplicate(find_duplicates(no_yawn_dir))

print(f"Número de imágenes de bostezos: {count_imgs(yawn_dir)}")
print(f"Número de imágenes de no bostezos: {count_imgs(no_yawn_dir)}")

"""# ***Data augmentation***


"""

def generate_data_augmentation(input_image_path, output_path, num_generated_images):
    # Carga la imagen
    img = load_img(input_image_path)
    img_array = img_to_array(img)
    img_array = img_array.reshape((1,) + img_array.shape)
    # Configura el generador de imágenes aumentadas
    datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    # Genera imágenes aumentadas y las guarda en el directorio especificado
    generated_images = []
    for i, batch in enumerate(datagen.flow(img_array, batch_size=1, save_to_dir=output_path, save_prefix='aug', save_format='jpeg')):
        generated_images.append(f"{output_path}/aug_{i}.jpeg")
        if i == num_generated_images - 1:
            break

    return generated_images

def apply_data_augmentation(input_directory, output_directory, num_imgs):
  # Lista de todas las imágenes en el directorio yawn_dir
  all_images = os.listdir(input_directory)
  # Selecciona 200 imágenes
  selected_images = random.sample(all_images, num_imgs)
  for img in selected_images:
    generate_data_augmentation(input_directory+"/"+img, output_directory, 1)

apply_data_augmentation(yawn_dir, yawn_dir, 152)#172
apply_data_augmentation(no_yawn_dir, no_yawn_dir, 1)#12

print(f"Número de imágenes de bostezos: {count_imgs(yawn_dir)}")
print(f"Número de imágenes de no bostezos: {count_imgs(no_yawn_dir)}")

"""# **Cargar Imagenes, Normalizado de pixeles y Transformación a Escala de Grises**"""

def load_and_preprocess_images(folder, label, grayscale=False, target_size=(200, 200)):
    images = []
    for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        if os.path.isfile(img_path):
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) if grayscale else cv2.imread(img_path)
            img = cv2.GaussianBlur(img, (3, 3), 0) # Aplicar filtro gaussiano
            img = cv2.resize(img, target_size)
            img_array = img.astype(np.float32) / 255.0
            images.append((img_array, label))
    return images

# Cargar y preprocesar imágenes
yawn_images = load_and_preprocess_images(yawn_dir, label=1)
no_yawn_images = load_and_preprocess_images(no_yawn_dir, label=0)

images = yawn_images + no_yawn_images

def extract_hog_features(image_path):
    # Lee la imagen
    image = io.imread(image_path)

    # Convierte la imagen a escala de grises
    gray_image = color.rgb2gray(image)

    # Aplica HOG
    features, hog_image = hog(gray_image, visualize=True)

    return features, hog_image

def visualize_hog(image_path):
    features, hog_image = extract_hog_features(image_path)

    # Visualiza la imagen original y la representación HOG
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)

    ax1.imshow(io.imread(image_path), cmap=plt.cm.gray)
    ax1.set_title('Imagen Original')

    # Ajusta el rango de valores para mejorar la visualización de HOG
    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))
    ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)
    ax2.set_title('Representación HOG')

    plt.show()
    return features

# Ejemplo de uso
image_path = yawn_dir+'/40.jpg'  # Reemplaza con la ruta de tu imagen
x3 = visualize_hog(image_path)

"""# **Extracción de Caracteristicas**"""

def extract_hog_features(images):
    hog_features = []
    for image, _ in images:
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if image.shape[-1] == 3 else image
        features = hog(gray_image, orientations=8, pixels_per_cell=(16, 16),
                       cells_per_block=(1, 1), block_norm='L2-Hys').flatten() / np.max(gray_image)
        hog_features.append(features)
    return np.array(hog_features)

X = extract_hog_features(images)

#X1 = np.array([item[0] for item in images])
y = np.array([label for _, label in images])

# DATASET division
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

unique_classes, counts = np.unique(y, return_counts=True)
print("Balance de clases:")
for cls, count in zip(unique_classes, counts):
    print(f"Clase {cls}: {count} imágenes")

# Verificar dimensiones
print("Dimensiones de las imágenes:", X_train.shape[:])  # Ignoramos la primera dimensión que corresponde al número de imágenes
print("Dimensiones de las imágenes:", X_test.shape[:])  # Ignoramos la primera dimensión que corresponde al número de imágenes

"""# **Matriz de Confusión y Medidas**"""

#scaler = MinMaxScaler()
#X_train_scaled = scaler.fit_transform(X_train)
#X_test_scaled = scaler.transform(X_test)

def modeloSVC(kernel,X,y,X_test,y_test):
  cls = SVC(kernel=kernel)
  #linear, RBF, poly, sigmoid
  cls.fit(X,y)
  print(cls.score(X,y))
  print(cls.score(X_test,y_test))
  return cls

cls = modeloSVC('rbf',X_train, y_train, X_test, y_test)#Train

#Train
y_pred = cls.predict(X_train)

print(classification_report(y_train,y_pred))

confusion_matrix(y_train,y_pred)

"""# **Creación del Modelo y Entrenamiento**"""

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(1152,), kernel_regularizer=regularizers.l2(0.01)))
model.add(Dropout(0.4))
model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(Dropout(0.4))
model.add(Dense(1, activation='sigmoid'))

y_train

# Define the model architecture
cnn = Sequential()
cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Conv2D(64, (3, 3), activation='relu'))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Conv2D(128, (3, 3), activation='relu'))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Conv2D(128, (3, 3), activation='relu'))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Flatten())
cnn.add(Dropout(0.5))
cnn.add(Dense(512, activation='relu'))
cnn.add(Dense(1, activation='sigmoid'))

#cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the cnn
#history = cnn.fit(X_train1, y_train, batch_size=32,validation_data=(X_test1, y_test),
    #                epochs=4, verbose=1)

# Compilar el modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar el modelo
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

loss = pd.DataFrame(model.history.history)
plt.figure(figsize=(15,5))
sns.lineplot(data=loss, lw=3)
sns.despine()

# Utiliza X_test e y_test, los datos de prueba, para evaluar el modelo
evaluation = model.evaluate(X_test, y_test)
print("Loss:", evaluation[0])
print("Accuracy:", evaluation[1])

y_pred = model.predict(X_test)

y_pred
y_pred = [round(pred[0]) for pred in y_pred]

print(classification_report(y_test,y_pred))

confusion_matrix(y_test,y_pred)

# Guardar el modelo
cnn.save('modelo_entrenado.pt')  # Guardar en un archivo

from google.colab import files
files.download('modelo_entrenado.pt')