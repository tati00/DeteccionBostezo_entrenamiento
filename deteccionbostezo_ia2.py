# -*- coding: utf-8 -*-
"""Copia de YawnModelCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lq90eCfLPcJ5vFm2vaMhTE6fAI70GBF0
"""

# Grupo: Esteban Bajaña, Erika Anrrango
import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
import random
from hashlib import md5
from PIL import Image
from sklearn.utils import shuffle
from sklearn.svm import SVC
import seaborn as sns
from skimage.feature import hog
from skimage import exposure, io, color
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from keras.preprocessing import image
from sklearn.metrics import classification_report, confusion_matrix
from skimage import exposure
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from tensorflow.keras.regularizers import l2
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from keras import regularizers
from keras.optimizers import Adam

from google.colab import files
uploaded = files.upload()

import zipfile # leer y escribir con archivos zip
import io # tener acceso a los archivos
data = zipfile.ZipFile(io.BytesIO(uploaded['dataset.zip']), 'r') # Leer el archivo 'r'
data.extractall() # extraer los archivos.

yawn_dir = "/content/dataset/yawn"
no_yawn_dir = "/content/dataset/no yawn"

def visualize_images(directory, num_images=5):
    # Obtener una lista de nombres de archivos en el directorio
    file_list = os.listdir(directory)[:num_images]
    # Configurar la cuadrícula de subgráficos
    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))
    for i, filename in enumerate(file_list):
        # Cargar y mostrar cada imagen
        path = os.path.join(directory, filename)
        img = Image.open(path)
        axes[i].imshow(img)
        axes[i].axis('off')  # Desactivar ejes para mayor claridad

    plt.show()

"""# *Redimensionamiento* de imagenes"""

def resize_images(directory, target_size):
    for filename in os.listdir(directory):
        path = os.path.join(directory, filename)
        img = Image.open(path)
        img_resized = img.resize(target_size)
        img_resized.save(path)

target_size = (64, 64)
resize_images(yawn_dir, target_size)
resize_images(no_yawn_dir, target_size)

visualize_images(yawn_dir, num_images=10)

def count_imgs(directorio):
    if not os.path.exists(directorio):
        print(f"El directorio {directorio} no existe.")
        return 0
    # Contador de imágenes
    num_imagenes = 0
    # Recorrer los archivos en el directorio
    for filename in os.listdir(directorio):
        path = os.path.join(directorio, filename)
        # Verificar si el elemento es un archivo y tiene una extensión de imagen
        if os.path.isfile(path) and any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):
            num_imagenes += 1
    return num_imagenes

def find_duplicates(directorio):
    hash_imagenes = {}
    # Lista para almacenar las imágenes duplicadas
    duplicadas = []
    # Recorrer los archivos en el directorio
    for filename in os.listdir(directorio):
        path = os.path.join(directorio, filename)
        # Verificar si el elemento es un archivo y tiene una extensión de imagen
        if os.path.isfile(path) and any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):
            # Calcular el hash MD5 de la imagen
            with open(path, 'rb') as f:
                hash_imagen = md5(f.read()).hexdigest()
            # Verificar duplicados
            if hash_imagen in hash_imagenes:
                duplicadas.append(path)
            else:
                hash_imagenes[hash_imagen] = path
    return duplicadas

def delete_duplicate(duplicadas):
    # Eliminar las imágenes duplicadas
    for duplicada in duplicadas:
        os.remove(duplicada)
    print(f"Total de imágenes duplicadas eliminadas: {len(duplicadas)}")

# Ejemplo de uso
delete_duplicate(find_duplicates(yawn_dir))
delete_duplicate(find_duplicates(no_yawn_dir))

print(f"Número de imágenes de bostezos: {count_imgs(yawn_dir)}")
print(f"Número de imágenes de no bostezos: {count_imgs(no_yawn_dir)}")

"""# ***Data augmentation***


"""

def generate_data_augmentation(input_image_path, output_path, num_generated_images):
    # Carga la imagen
    img = load_img(input_image_path)
    img_array = img_to_array(img)
    img_array = img_array.reshape((1,) + img_array.shape)
    # Configura el generador de imágenes aumentadas
    datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    # Genera imágenes aumentadas y las guarda en el directorio especificado
    generated_images = []
    for i, batch in enumerate(datagen.flow(img_array, batch_size=1, save_to_dir=output_path, save_prefix='aug', save_format='jpeg')):
        generated_images.append(f"{output_path}/aug_{i}.jpeg")
        if i == num_generated_images - 1:
            break

    return generated_images

def apply_data_augmentation(input_directory, output_directory, num_imgs):
  # Lista de todas las imágenes en el directorio yawn_dir
  all_images = os.listdir(input_directory)
  # Selecciona 200 imágenes
  selected_images = random.sample(all_images, num_imgs)
  for img in selected_images:
    generate_data_augmentation(input_directory+"/"+img, output_directory, 1)

#apply_data_augmentation(yawn_dir, yawn_dir, 224)
#apply_data_augmentation(no_yawn_dir, no_yawn_dir, 72)#

print(f"Número de imágenes de bostezos: {count_imgs(yawn_dir)}")
print(f"Número de imágenes de no bostezos: {count_imgs(no_yawn_dir)}")

import shutil
from google.colab import drive

# Montar Google Drive en Colab
drive.mount('/content/gdrive')

"""# **Cargar Imagenes, Normalizado de pixeles y Transformación a Escala de Grises**"""

from google.colab import drive
drive.mount('/content/drive')

yawn_path = "/content/drive/MyDrive/Data_Model/yawn"
no_yawn_path = "/content/drive/MyDrive/Data_Model/no yawn"

def load_and_preprocess_images(folder, label, grayscale=False):
  images = []
  for filename in os.listdir(folder):
        img_path = os.path.join(folder, filename)
        if os.path.isfile(img_path):
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            img = cv2.GaussianBlur(img, (3, 3), 0)  # Aplicar filtro gaussiano
            img_array = img.astype(np.float32) / 255.0
            images.append((img_array, label))
  return images

# Cargar y preprocesar imágenes
yawn_images = load_and_preprocess_images(yawn_dir, label=1)
no_yawn_images = load_and_preprocess_images(no_yawn_dir, label=0)

print(f"Número de imágenes de bostezos: {count_imgs(yawn_path)}")
print(f"Número de imágenes de no bostezos: {count_imgs(no_yawn_path)}")

images = yawn_images + no_yawn_images

"""# **Split del Dataset**"""

X = np.array([item[0] for item in images])
y = np.array([label for _, label in images])

# DATASET division
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)

unique_classes, counts = np.unique(y, return_counts=True)
print("Balance de clases:")
for cls, count in zip(unique_classes, counts):
    print(f"Clase {cls}: {count} imágenes")

# Verificar dimensiones
print("Dimensiones de las imágenes:", X_train.shape[:])  # Ignoramos la primera dimensión que corresponde al número de imágenes
print("Dimensiones de las imágenes:", X_test.shape[:])  # Ignoramos la primera dimensión que corresponde al número de imágenes

"""# **Creación del Modelo y Entrenamiento**"""

cnn = Sequential()

cnn.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Dropout(rate=0.4))
cnn.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Dropout(rate=0.5))
cnn.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)))
cnn.add(MaxPooling2D((2, 2)))
cnn.add(Flatten())
cnn.add(Dense(128, activation='relu'))
cnn.add(Dropout(rate=0.5))
cnn.add(Dense(64, activation='relu'))
cnn.add(Dense(1, activation='sigmoid'))

cnn.build(input_shape=(None, 64, 64, 1))
cnn.summary()

cnn.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])
# Train the cnn
history = cnn.fit(X_train, y_train, batch_size=35,validation_data=(X_test, y_test),
                   epochs=65)

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(accuracy))

plt.plot(epochs, accuracy, "b", label="trainning accuracy")
plt.plot(epochs, val_accuracy, "r", label="validation accuracy")
plt.legend()
plt.show()

plt.plot(epochs, loss, "b", label="trainning loss")
plt.plot(epochs, val_loss, "r", label="validation loss")
plt.legend()
plt.show()

# Utiliza X_test e y_test, los datos de prueba, para evaluar el modelo
evaluation = cnn.evaluate(X_test, y_test)
print("Loss:", evaluation[0])
print("Accuracy:", evaluation[1])

y_pred_train = cnn.predict(X_train)
y_pred_train = (y_pred_train > 0.5).astype(int)

y_pred_test = cnn.predict(X_test)
y_pred_test = (y_pred_test > 0.5).astype(int)

"""# **Matriz de Confusión y Medidas**"""

print(classification_report(y_train,y_pred_train))

confusion_matrix(y_train,y_pred_train)

print(classification_report(y_test,y_pred_test))

confusion_matrix(y_test,y_pred_test)

# Guardar el modelo
cnn.save('Yawnmodel_cnn.h5')

from google.colab import files

# Descargar el modelo
files.download('Yawnmodel_cnn.h5')